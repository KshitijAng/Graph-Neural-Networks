# Graph Neural Networks (GNNs)

## ğŸ“Œ Introduction
A **Graph Neural Network (GNN)** is a type of neural network designed to process **graph-structured data**. Unlike traditional neural networks that work on grids (e.g., images) or sequences (e.g., text), GNNs operate on **nodes, edges, and their relationships**. GNNs are especially useful for handling **non-Euclidean data**, such as:

- **Social Networks** (e.g., friend connections, influencer detection)
- **Biological Networks** (e.g., molecular interactions, protein folding)
- **Traffic Networks** (e.g., roadmaps, sensor networks)

---
## ğŸ“Š Graph Data Structure
A graph consists of:
- **Nodes (Vertices)** â†’ Represent entities.
- **Edges** â†’ Define relationships between nodes.
- **Features** â†’ Store relevant data associated with nodes or edges.

Graphs are represented using an **Adjacency Matrix**, a square matrix of size **V Ã— V** (where V is the number of nodes), indicating connections between nodes.

### ğŸ›ï¸ Types of Graphs
#### ğŸ”„ **Based on Direction:**
- **Directed Graph** â†’ Edges have a direction (A â†’ B).
- **Undirected Graph** â†’ Edges have no direction (A â€” B).

#### âš– **Based on Weights:**
- **Weighted Graph** â†’ Edges have associated weights (e.g., cost, distance, or probability).
- **Unweighted Graph** â†’ All edges are equal (no weights assigned).

---
## ğŸ¯ Tasks Done with GNNs
GNNs are used for different tasks at various levels:

### 1ï¸âƒ£ **Node-Level Tasks**
- **Node Classification** â†’ Predict the label/class of a node (e.g., identifying fraud accounts in a network).

### 2ï¸âƒ£ **Edge-Level Tasks**
- **Edge Prediction** â†’ Predict the existence or strength of a connection (e.g., friend recommendation in social networks).

### 3ï¸âƒ£ **Graph-Level Tasks**
- **Graph Classification** â†’ Classify an entire graph (e.g., predicting whether a molecular structure is toxic or not).

---
## ğŸ› ï¸ How GNNs Work
A GNN follows these steps:

- 1ï¸âƒ£ **Initialization** â†’ Convert all feature vectors into node embeddings.
- 2ï¸âƒ£ **Message Passing** â†’ Nodes exchange information with neighboring nodes to update their representation.
- 3ï¸âƒ£ **Message Aggregation** â†’ Combine messages from neighbors using aggregation functions (sum, mean, max, etc.).
- 4ï¸âƒ£ **Node Updation** â†’ Update the node representation based on aggregated messages.

ğŸ”¹ These steps repeat over multiple layers to learn deeper node representations.

## ğŸ“š Further Learning Resources
- [PyTorch Geometric Documentation](https://pytorch-geometric.readthedocs.io/)
- [Stanford CS224W: Machine Learning with Graphs](http://web.stanford.edu/class/cs224w/)

Happy Coding! ğŸš€

